max_epochs: 30
batch_size: 32
num_workers: 8
learning_rate: 0.00008
weight_decay: 0.05

ldam_margin: 0.48
ldam_scale: 30.0
lambda_contrast: 0.0
temperature: 0.07

mixup_alpha: 0.2
cutmix_prob: 0.3

mixed_precision: true
gradient_clip: 1.0
accumulate_grad: 1
patience: 10
