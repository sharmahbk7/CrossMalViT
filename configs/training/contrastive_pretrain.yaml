max_epochs: 50
batch_size: 64
num_workers: 8
learning_rate: 0.0002
weight_decay: 0.03

ldam_margin: 0.0
ldam_scale: 30.0
lambda_contrast: 1.0
temperature: 0.07

mixup_alpha: 0.2
cutmix_prob: 0.0

mixed_precision: true
gradient_clip: 1.0
accumulate_grad: 1
patience: 10
