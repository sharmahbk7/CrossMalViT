"""Kaggle Malware Images dataset implementation."""

from typing import Callable, Dict, List, Optional, Tuple
from pathlib import Path
import pandas as pd
from PIL import Image
import torch
from torch.utils.data import Dataset


class KaggleMalwareDataset(Dataset):
    """Kaggle Malware Images Dataset."""

    CLASSES = [
        "Allaple.A",
        "Allaple.L",
        "Yuner.A",
        "Lolyda.AA1",
        "Lolyda.AA2",
        "Lolyda.AA3",
        "C2Lop.P",
        "C2Lop.gen!g",
        "Instantaccess",
        "Swizzor.gen!E",
        "Swizzor.gen!I",
        "VB.AT",
        "Fakerean",
        "Alueron.gen!J",
        "Malex.gen!J",
        "Autorun.K",
        "Rbot!gen",
        "Benign",
    ]

    NUM_CLASSES = 18

    def __init__(
        self,
        root: str,
        split: str = "train",
        transform: Optional[Callable] = None,
        multi_view_transform: Optional[Callable] = None,
        img_size: int = 224,
    ) -> None:
        self.root = Path(root)
        self.split = split
        self.transform = transform
        self.multi_view_transform = multi_view_transform
        self.img_size = img_size

        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.CLASSES)}
        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}

        self.samples = self._load_samples()
        self.class_counts = self._compute_class_counts()
        self.class_weights = self._compute_class_weights()

    def _load_samples(self) -> List[Tuple[str, int]]:
        samples: List[Tuple[str, int]] = []

        split_file = self.root / f"{self.split}.csv"
        if split_file.exists():
            df = pd.read_csv(split_file)
            for _, row in df.iterrows():
                img_path = self.root / row["path"]
                label = self.class_to_idx[row["label"]]
                samples.append((str(img_path), label))
        else:
            for class_name in self.CLASSES:
                class_dir = self.root / class_name
                if class_dir.exists():
                    for img_file in class_dir.glob("*.png"):
                        label = self.class_to_idx[class_name]
                        samples.append((str(img_file), label))

        return samples

    def _compute_class_counts(self) -> Dict[int, int]:
        counts = {i: 0 for i in range(self.NUM_CLASSES)}
        for _, label in self.samples:
            counts[label] += 1
        return counts

    def _compute_class_weights(self) -> torch.Tensor:
        total = sum(self.class_counts.values())
        weights = torch.zeros(self.NUM_CLASSES)
        for idx, count in self.class_counts.items():
            weights[idx] = total / (self.NUM_CLASSES * count) if count > 0 else 0
        return weights

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert("L")
        image = image.resize((self.img_size, self.img_size), Image.BILINEAR)

        if self.transform:
            image = self.transform(image)

        if self.multi_view_transform:
            views = self.multi_view_transform(image)
        else:
            import numpy as np

            img_array = np.array(image).astype("float32") / 255.0
            views = {
                "raw": torch.from_numpy(img_array).unsqueeze(0),
                "entropy": torch.from_numpy(img_array).unsqueeze(0),
                "frequency": torch.from_numpy(img_array).unsqueeze(0),
            }

        views["label"] = torch.tensor(label, dtype=torch.long)
        views["index"] = torch.tensor(idx, dtype=torch.long)

        return views

    def get_class_distribution(self) -> Dict[str, int]:
        return {self.idx_to_class[idx]: count for idx, count in self.class_counts.items()}


def create_data_splits(
    root: str,
    train_ratio: float = 0.7,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15,
    seed: int = 42,
) -> None:
    """Create stratified train/val/test splits and save to CSV files."""
    from sklearn.model_selection import train_test_split
    import numpy as np

    np.random.seed(seed)
    root_path = Path(root)

    all_samples = []
    for class_name in KaggleMalwareDataset.CLASSES:
        class_dir = root_path / class_name
        if class_dir.exists():
            for img_file in class_dir.glob("*.png"):
                all_samples.append({"path": str(img_file.relative_to(root_path)), "label": class_name})

    df = pd.DataFrame(all_samples)

    train_val, test = train_test_split(
        df, test_size=test_ratio, stratify=df["label"], random_state=seed
    )
    train, val = train_test_split(
        train_val,
        test_size=val_ratio / (1 - test_ratio),
        stratify=train_val["label"],
        random_state=seed,
    )

    train.to_csv(root_path / "train.csv", index=False)
    val.to_csv(root_path / "val.csv", index=False)
    test.to_csv(root_path / "test.csv", index=False)

    print(f"Created splits: train={len(train)}, val={len(val)}, test={len(test)}")
